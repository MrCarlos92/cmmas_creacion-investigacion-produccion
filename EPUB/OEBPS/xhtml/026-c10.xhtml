<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="es" lang="es">
    <head>
        <meta charset="UTF-8" />
        <title>Investigación y creación en música electroacústica: composición y performance con sistemas multicanales y interfaces gestuales</title>
        <link href="../css/principal.css" rel="stylesheet" type="text/css" />
    </head>
    <body epub:type="chapter">
        <section>
            <h1 id="danielLuísBarreiro">Investigación y creación en música electroacústica: composición y <em>performance</em> con sistemas multicanales e interfaces gestuales<sup><span id="nota1"><a href="027-n10.xhtml#nota1"><span class="sup">1</span></a></span></sup></h1>
            <p class="centrado">Daniel Luís Barreiro</p>
        </section>
        <section>
            <h2 id="introducción-3">Introducción</h2>
            <p>En mi trabajo, la creación artística en el contexto de la producción académica significa buscar formas de aliar composición y <em>performance</em> musical al ejercicio reflexivo –sobre el propio proceso de creación, sobre la recepción artística, sobre aspectos estéticos, técnicos y/o conceptuales. La actividad de creación está comprometida con la concepción y la realización de un objeto/proceso artístico en/para un determinado contexto (composición para concierto, instalación interactiva o improvisación, por ejemplo). Además del ámbito de la concepción de la obra/proceso y del trabajo de manipulación de los materiales en el proceso de creación, la realización involucra también, en mi caso, el desarrollo de aplicativos –<a href="https://cycling74.com/"><em>patches</em></a>, generalmente en el ambiente Max/MSP– para la síntesis y procesamiento sonoro en tiempo real. En mis investigaciones, que generalmente apuntan hacia la música electroacústica y algunas de sus derivaciones, esa esfera de la producción técnica (desarrollo de <em>patches</em>) se vincula íntimamente a la esfera composicional/performativa más propiamente dicha (de manipulación de los materiales sonoros y realización de la obra/<em>performance</em>). Considerándose que, en el ámbito de las poéticas musicales contemporáneas, la composición de los sonidos<sup><span id="nota2"><a href="027-n10.xhtml#nota2">2</a></span></sup> constituye aspectos fundamentales del pensamiento composicional, me parece innegable que el desarrollo de los <em>patches</em> para generar los sonidos constituya parte integrante de la actividad creativa en el campo de la música electroacústica. De esta forma, en mi trabajo, la actividad composicional/de <em>performance</em> y el desarrollo de <em>patches</em> se fomentan mutuamente, de forma que, las concepciones para el desarrollo de un <em>patch</em>, deriven de una idea musical y viceversa.</p>
            <p>Dentro de esa concepción general, el texto que sigue discute algunas cuestiones presentes en mis investigaciones que se presentan de forma convergente en la composición de mi obra <em>Weaving Rust</em> (2013-2014), para sonidos electroacústicos en 24 canales.<sup><span id="nota3"><a href="027-n10.xhtml#nota3">3</a></span></sup> El abordaje de la obra refiere a cuestiones relacionadas a la espacialidad en la composición electroacústica con sistemas multicanales –más precisamente la concepción de composición en <em>stems</em>– además del uso de interfaces de control gestual y del desarrollo de <em>patches</em> en el ambiente Max/MSP. Este abordaje exige una retrospectiva sobre concepciones y trabajos anteriores, que es aquí mencionada con el objetivo de ilustrar uno de los muchos posibles caminos de creación artística en el contexto de la producción académica en la actualidad.</p>
            <h2 id="espacio">Espacio</h2>
            <p>El tratamiento del espacio ha sido una de las cuestiones más importantes en mi trabajo composicional, sobre todo desde mi investigación de doctorado.<sup><span id="nota4"><a href="027-n10.xhtml#nota4">4</a></span></sup> La oportunidad de actuar junto al <a href="http://www.beast.bham.ac.uk/">Birmingham Electro-Acoustic Sound Theatre</a> (BEAST) me ha posibilitado, en diversas ocasiones y en diferentes espacios de concierto, experimentar el proceso de montaje del sistema sonoro, lo que ha proporcionado una comprensión profunda sobre su concepción, la elección y la disposición de los varios altoparlantes, la configuración de los <em>faders</em> en la mesa de difusión para el control de los canales de audio, entre otros aspectos. Fue sobre todo fundamental la oportunidad de desarrollar la práctica de difusión sonora con el sistema BEAST –inicialmente en la presentación de mis obras y de otros compositores compuestas en <em>stereo</em>, pero posteriormente también de obras compuestas para sistemas multicanales (ocho canales, principalmente). La experiencia de potencializar el espacio compuesto de las obras (o sea, el espacio concebido durante el estadío composicional), articulando la obra en la sala de concierto (espacio de escucha) por medio de la difusión sonora con varias decenas de altoparlantes,<sup><span id="nota5"><a href="027-n10.xhtml#nota5">5</a></span></sup> me ha proporcionado la comprensión de que los sonidos no sólo ocupan un espacio preexistente, sino sobre todo moldean/esculpen ese espacio –o sea, constituyen el espacio percibido por la escucha. La posibilidad de esculpir el espacio con sonidos –lo que, aunque ya ocurra en obras en <em>stereo</em>, gana una dimensión substancialmente más ampliada y envolvente con un número más grande de altoparlantes– pasó entonces a orientar de forma más enfática mi actividad en el estudio de música electroacústica por medio de la composición de obras en ocho canales –<em>Percursos Enredados</em> (2005), <em>Maresia</em> (2005-2006), <em>Sons Adentro</em> (2006) y <em>Open Field</em> (2006), las cuales utilizan la siguiente configuración de altoparlantes (figura 1).<sup><span id="nota6"><a href="027-n10.xhtml#nota6">6</a></span></sup></p>

            <figure>
              <img src="../img/figura3.png" alt="Figura 1" />
              <figcaption>Fig.&#160;1: Disposición de los ocho altoparlantes en mis composiciones octofónicas.</figcaption>
            </figure>

            <p>Hay diferentes estrategias para moldear el espacio en ocho canales durante el proceso composicional de una obra electroacústica. Una de las alternativas es el control de la amplitud de los sonidos en cada uno de los canales, lo que, según sostuve (Barreiro 2010, p. 291), tiende a ser un abordaje eficaz cuando se busca establecer precisamente la posición y el movimiento de los sonidos en el espacio (a partir de muestras sonoras mono o estereofónicas, por ejemplo). Para la elaboración de muchos de los materiales que constituyen las obras anteriormente mencionadas, busqué, en diversos momentos, obtener un resultado sonoro difuso –y, muchas veces, envolvente alrededor del público. En una situación como esta, «la identificación de regiones espaciales como "frontal", "lateral", "en la periferia del espacio", "próxima" y "distante", por ejemplo, son consideradas como suficientemente significativas para articular la dimensión espacial de una obra» (Barreiro, 2010, p. 291). En varios momentos busqué producir sonidos generados por los ocho canales conjuntamente. En esa época, yo estaba interesado, así como otros colegas de la University of Birmingham y de mi tutor Jonty Harrison, a programar <em>patches</em> en Max/MSP con el objetivo de procesar en ocho canales las muestras de audio grabadas originalmente en <em>stereo</em> (o mono, ocasionalmente).<sup><span id="nota7"><a href="027-n10.xhtml#nota7">7</a></span></sup> En mi caso, la programación de <em>patches</em> estuvo relacionada a la composición de las obras mencionadas anteriormente. Partiendo de muestras <em>stereo</em> como material fuente, fue posible obtener resultados envolventes en el tratamiento del espacio por medio de diferentes procesamientos de los sonidos, utilizando técnicas de difusión espectral y granulación en ocho canales implementadas en <em>patches</em> desarrollados en Max/MSP –ver: Barreiro (2010)–.</p>
            <p>En mi investigación de posdoctorado, realizada en Novars Research Centre, en la University of Manchester, he explorado nuevos abordajes sobre tratamiento del espacio en la composición de una obra electroacústica en veinticuatro canales, cuyo título es <em>Weaving Rust</em>.<sup><span id="nota8"><a href="027-n10.xhtml#nota8">8</a></span></sup> El aumento del número de canales en relación a las obras anteriores correspondió a una mayor complejidad en el tratamiento de los aspectos técnicos y en la elaboración musical. He optado por utilizar el abordaje de «composición en <em>stems</em>», explorada por Wilson y Harrison (2010, p. 245).<sup><span id="nota9"><a href="027-n10.xhtml#nota9">9</a></span></sup> Según los autores, el término y el abordaje por <em>stems</em> son tomados (y adaptados) de la práctica de masterización, en la cual los ingenieros de sonido agrupan eventos de la obra en <em>submixes</em> diferentes para controlarlos mejor (o sea, controlarlos de forma independiente) en el momento de la masterización final. Adaptando el abordaje para el campo de la práctica electroacústica, la composición en <em>stems</em> consiste en «separar elementos que necesitan ser tratados separadamente en la espacialización final» –por ejemplo, cuando el compositor "imagina una pieza constituida de dos <em>stems</em> de ocho canales, una concebida para ser localizada a la altura de las orejas<sup><span id="nota10"><a href="027-n10.xhtml#nota10">10</a></span></sup> y otra concebida para sonar más arriba"; o aun cuando imaginese «una pieza constituida de <em>stems</em> en primer plano y plano de fondo, o elementos en figura y elementos del ambiente,<sup><span id="nota11"><a href="027-n10.xhtml#nota11">11</a></span></sup> o cuando se distingue entre las <em>stems</em> móviles en oposición a las <em>stems</em> estáticas» (Wilson &amp; Harrison, 2010, p. 245). Según los autores, ese abordaje es especialmente útil en el caso de obras compuestas para un gran número de canales discretos, teniendo en cuenta que no hay patrones de configuración de posicionamientos de los altoparlantes para un número más grande que ocho canales.</p>
            <p>En el caso de <em>Weaving Rust</em>, la obra fue concebida en tres <em>stems</em> distintas, de ocho canales cada una (figura 2). Son ellas:</p>
            <ul>
                <li><p><em>High Stem</em> (canales del 1 al 8): constituida principalmente por sonidos granulares de espectro complejo concentrados en el registro agudo. Fue concebida para sonar en una altura más elevada que el público (con los altoparlantes posicionados en pedestales altos, o sostenidos desde el techo, o aún, posicionados en un entrepiso de la sala del concierto).</p></li>
                <li><p><em>Main Stem</em> (canales del 9 al 16): constituida por los eventos del primer plan de la obra, dotados de carácter gestual. Fue concebida para sonar a la altura de los oídos ­–<em>ear-level</em> (con altoparlantes alrededor del público);</p></li>
                <li><p><em>Distant Stem</em> (canales del 17 al 24): basada en sonidos largos y de evolución lenta, constituyendo camadas sonoras que envuelven todo el ambiente y actúan como plano de fondo de la obra. Fue concebida para sonar en un grupo de ocho altoparlantes más distantes del público que la <em>Main Stem</em> (pudiendo, para aumentar la sensación de más distancia, ser direccionada con los altoparlantes apuntados para las paredes de la sala de concierto, para que el público escuche el sonido reflejado).</p></li>
            </ul>

            <figure>
              <img src="../img/figura4.png" alt="Figura 2" />
              <figcaption>Fig.&#160;2 Disposición de las stems en los altoparlantes en <em>Weaving Rust</em>.</figcaption>
            </figure>

            <p>La obra fue inicialmente compuesta en versión acusmática, concebida y realizada en el estudio de música electroacústica.<sup><span id="nota12"><a href="027-n10.xhtml#nota12">12</a></span></sup> Posteriormente, compuse otras versiones en las cuales el contenido sonoro de algunas de las <em>stems</em> podría ser generado en tiempo real en el momento del <em>performance</em>, utilizando una interfaz de control gestual ­–o <a href="https://www.leapmotion.com/">Leap Motion</a>– asociada a <em>patches</em> desarrollados en Max/MSP. Antes de abordar esa característica, vale, con todo caso, destacar como fue elaborada la distribución de las stems en los altoparlantes en dos ocasiones de presentación de la versión acusmática de <em>Weaving Rust</em> en concierto.</p>
            <p><em>Weaving Rust</em> fue presentada primero con el sistema MANTIS (Manchester Theatre in Sound), con más de cuarenta canales independientes de audio, en el Cosmo Rodewald Concert Hall, en la University of Manchester, en el MANTIS Festival of Electroacoustic Music – March 2014. En esa ocasión, cada una de las <em>stems</em> de la obra fue direccionada para más de un grupo de altoparlantes y los veinticuatro canales fueron reproducidos por cuarenta altoparlantes y dos <em>subwoofers</em>, de acuerdo con los diagramas abajo (figuras 3, 4 y 5).<sup><span id="nota13"><a href="027-n10.xhtml#nota13">13</a></span></sup></p>

            <figure>
              <img src="../img/figura5.png" alt="Figura 3" />
              <figcaption>Fig.&#160;3. Diagrama (en verde) de direccionamiento de <em>High Stem</em> para ocho altoparlantes posicionados en un entrepiso y en el techo de la sala de concierto y para cuatro altoparlantes más cerca del público.</figcaption>
            </figure>

            <figure>
              <img src="../img/figura6.png" alt="Figura 4" />
              <figcaption>Fig.&#160;4: Diagrama (en rojo) de direccionamiento de la <em>Main Stem</em> para un grupo de ocho altoparlantes (círculo), un grupo de cuatro altoparlantes (rectángulo grande) posicionados alrededor del público a la altura de las orejas y para un grupo de cuatro altoparlantes posicionados alrededor de la mesa de difusión.</figcaption>
            </figure>

            <figure>
              <img src="../img/figura7.png" alt="Figura 5" />
              <figcaption>Fig.&#160;5: Diagrama (en violeta) de direccionamiento de la <em>Distant Stem</em> para un grupo de ocho altoparlantes posicionados en las extremidades de la sala de concierto y apuntados hacia las paredes y un grupo de cuatro altoparlantes (cuadrilátero más pequeño) posicionado más cerca del público.</figcaption>
            </figure>

            <p>La separación de los materiales sonoros por <em>stem</em> permitió concebir como cada una de ellas se distribuía en los altoparlantes considerando sus características y funciones en el tejido sonoro de la obra. La opción de utilizar más que ocho altoparlantes para la reproducción de cada <em>stem</em> permitió, por medio de la difusión sonora, potencializar el tratamiento del espacio concebido en la composición, explorando separadamente el juego de aproximación o de distanciamiento de cada <em>stem</em> en relación al público en momentos específicos del discurso musical.</p>
            <p>Ese tipo de concepción también estuvo presente en la presentación de <em>Weaving Rust</em> con el sistema PUTS (PANaroma/UNESP – Teatro Sonoro), con 52 canales independientes de audio (ver figura 6), en la X BIMESP (Bienal Internacional de Música Electroacústica de São Paulo), realizada en el Teatro Maria de Lourdes Sekeff, en el Instituto de Artes de la Unesp, en San Paulo, en octubre de 2014.</p>

            <figure>
              <img src="../img/figura8.png" alt="Figura 6" />
              <figcaption>Fig.&#160;6. Configuración del sistema PUTS en la <a href="http://flomenezes.mus.br/panaroma/index_panaroma.html">X BIMESP</a>. <br /> <a target="_blank" href="http://flomenezes.mus.br/panaroma/puts/puts_photos/PUTS_configuration-2014.jpg">Fuente</a> [Fecha de acceso: 10/01/17]</figcaption>
            </figure>

            <p>En este caso, la <em>High Stem</em> fue direccionada para sonar en los altoparlantes Meyer, posicionados en las laterales de la sala de concierto a una altura más elevada de que los altoparlantes Mackie que reprodujeron la <em>Main Stem</em>. Los canales 1 y 2 de la <em>High Stem</em> fueron también direccionados para altoparlantes frontales del sistema PUTS con el fin de presentar una imagen acústica frontal llena. Para permitir que, en el momento de la difusión, se pueda conseguir una mayor aproximación del sonido en relación al público, la <em>High Stem</em> fue también direccionada (en reducción cuadrafónica) para cuatro altoparlantes próximos al público. La <em>Distant Stem</em>, a su vez, fue direccionada para los ocho altoparlantes colgados en el techo (posicionados más arriba de los altoparlantes Meyer). Con base en la concepción original de la obra, se puede pensar que sería más natural direccionar la reproducción de la <em>High Stem</em> (y no de la <em>Distant Stem</em>) para estos altoparlantes. Sin embargo, las características de reproducción sonora de estos altoparlantes y la disposición en que se encontraban (o sea, el hecho de que no estaban dispuestos en parejas como para crear una elipsis), reveló que ellos se adecuaban a la reproducción de la <em>Distant Stem</em> (considerando que esta tiene como base la utilización de sonidos largos, difusos y envolventes, concebidos sin la preocupación para que las precisas trayectorias fuesen identificadas). La <em>Distant Stem</em> fue también direccionada (en reducción cuadrafónica) para cuatro altoparlantes posicionados en el fondo del escenario –distantes, por lo tanto, del público. La <em>Main Stem</em>, de acuerdo con lo que ha sido mencionado anteriormente, fue direccionada para los ocho altoparlantes principales del sistema PUTS, de marca Mackie, posicionados alrededor del público (ver figura 6).</p>
            <h2 id="interfaces-gestuales">Interfaces gestuales</h2>
            <p>Inicialmente compuesta como una obra acusmática, <em>Weaving Rust</em> ha implicado también otras concepciones, o versiones, que permitieran generar y controlar sonidos electroacústicos en tiempo real en el momento del <em>performance</em>. Fueron investigados, así, el concepto de <em>live-acousmatic music</em>, formulado por Berezan (2008), y la idea de <em>fracturing the acousmatic</em>, formulada por Moore (2008), que constituyen abordajes híbridos que combinan la elaboración minuciosa del material musical en el estudio (típica de la música acusmática) con la flexibilidad de la improvisación con los sonidos electroacústicos generados en tiempo real en el momento del <em>performance</em> (típica de la <em>laptop music</em>). En otras palabras, fue explorado «un camino intermedio entre la fijeza de la música acusmática y la música electroacústica en vivo/improvisada, utilizando la difusión sonora en vivo como punto de partida» (Berezan, 2008, p. 1).</p>
            <p>La posibilidad de desarrollar versiones de <em>Weaving Rust</em> en que, camadas sonoras generadas en tiempo real interactuasen con camadas compuestas en estudio, ofreció la oportunidad de experimentar situaciones de improvisación direccionada-<sup><span id="nota14"><a href="027-n10.xhtml#nota14">14</a></span></sup> en el <em>performance</em> de la obra con sistemas multicanales; abordando, así, diferentes grados de participación de estos sonidos generados en tiempo real para la constitución del tejido sonoro general de la obra.</p>
            <p>En los últimos años ha habido un desarrollo de las tecnologías pautadas en formas más directas e intuitivas de interacción entre hombre y máquina, tales como pantallas sensibles al toque y sensores de movimiento, que abrieron interesantes perspectivas al campo del arte interactivo por medio del uso adaptado de <em>smartphones</em>, <em>tablets</em> y controles de videojuegos, por ejemplo. El trabajo en cuestión partió del principio de que la actual tecnología de rastreo de movimientos ofrece herramientas eficientes y versátiles para permitir que, con el desarrollo de aplicaciones específicas, el compositor/<em>performer</em> de música electroacústica controle simultáneamente varios parámetros sonoros con el movimiento de las manos/dedos, o sea, que pueda moldear/esculpir de forma más intuitiva y directa las cualidades internas y los comportamientos de los sonidos en el tiempo y en el espacio. En una situación de <em>performance</em> en vivo, ese abordaje posee el potencial de atribuir más dinamismo y gestualidad en la manipulación de las características espectromorfológicas y en el tratamiento espacial de los sonidos –ver: Fischman (2013) para un ejemplo con tales características–, si fueran comparadas con las formas de interacción que no permiten el control de parámetros diferentes en simultaneo.</p>
            <p>En mis investigaciones realizadas en la Universidad Federal de Uberlândia, estaba buscando desarrollar <em>patches</em> para el control de sonidos electroacústicos en situaciones de improvisación con el uso de interfaces gestuales, o sea, de dispositivos capaces de rastrear movimientos corporales en los tres ejes espaciales, permitiendo el mapeo de datos para controlar diferentes parámetros sonoros simultáneamente durante un <em>performance</em>.<sup><span id="nota15"><a href="027-n10.xhtml#nota15">15</a></span></sup> Esta perspectiva fue, entonces, incorporada a la investigación en la cual la composición de <em>Weaving Rust</em> se desarrolló.</p>
            <p>Para crear formas de control de sonidos electroacústicos en tiempo real para la presentación de <em>Weaving Rust</em>, realicé, inicialmente, una lista de dispositivos de rastreo de movimiento (interfaces gestuales) que podrían ser utilizados para el control de los procesos de síntesis, procesamiento y espacialización sonoro en tiempo real. Trabajos que he realizado con el Wiimote/nunchuk y el Kinect, ya habían demostrado sus aspectos positivos y negativos.<sup><span id="nota16"><a href="027-n10.xhtml#nota16">16</a></span></sup> De ese modo, centré la atención en el Leap Motion, que es un dispositivo con conexión USB portátil y discreto, dotado de cámaras y emisor infrarrojo, que rastrea los movimientos de las manos y de cada uno de los dedos individualmente en los tres ejes espaciales con precisión milimétrica y sin retraso perceptible, permitiendo el control simultáneo de varios parámetros con base en las coordenadas espaciales y en la velocidad/aceleración de los movimientos.</p>
            <p>Para establecer la comunicación de los datos captados por el Leap Motion con el ambiente Max/MSP, utilicé el objeto (<em>external</em>) <em>aka.leapmotion</em>, de <a href="http://akamatsu.org/aka/max/objects/">Masayuki Akamatsu</a>. Este objeto ofrece el control dentro del Max/MSP (o sea, sin la necesidad del un software adicional) de innumerables datos, tales como:</p>
            <ul>
                <li><p>número de manos identificadas;</p></li>
                <li><p>número de dedos no contraídos (no cerrados);</p></li>
                <li><p>posición y aceleración de cada una de las manos en los tres ejes espaciales;</p></li>
                <li><p>posición y aceleración de cada uno de los dedos en los tres ejes espaciales.</p></li>
            </ul>
            <p>La programación de uno de los <em>patches</em> en Max/MSP para utilizar en el <em>performance</em> de <em>Weaving Rust</em> se basó en mis implementaciones anteriores que ya había realizado con el Wiimote/nunchuk y con el Kinect.</p>
            <p>Dotados de acelerómetros, sensor infrarrojo, diversos botones y <em>joysticks</em>, el Wiimote y el nunchuk permitieron, en trabajos anteriores, controlar simultáneamente diversos parámetros que fueron mapeados para los procesos de síntesis, procesamiento y espacialización sonora en tiempo real. De todas las aplicaciones que desarrollé con el Wiimote/nunchuk, destaco las siguientes:<sup><span id="nota17"><a href="027-n10.xhtml#nota17">17</a></span></sup></p>
            <ul>
                <li><p><em>patch</em> (en Max/MSP) para controlar la grabación y la reproducción de muestras sonoras en diversas camadas simultáneas;</p></li>
                <li><p><em>patch</em> (en <a href="https://puredata.info/">Pd</a>) para controlar la reproducción y el procesamiento en camadas simultáneas de muestras sonoras pregrabadas;<sup><span id="nota18"><a href="027-n10.xhtml#nota18">18</a></span></sup></p></li>
                <li><p><em>patch</em> (en Max/MSP) para el control de la síntesis aditiva;</p></li>
                <li><p><em>patch</em> (en Max/MSP) para el control en cuatro canales de granulaciones de muestras pregrabadas (<em>granular sampling</em>).<sup><span id="nota19"><a href="027-n10.xhtml#nota19">19</a></span></sup></p></li>
            </ul>
            <p>No cabe aquí detallar el funcionamiento de cada uno de estos <em>patches</em>, algunos de los cuales fueron abordados en otros trabajos –ver: Barreiro at al. (2010); Barreiro (2011); Traldi et al. (2011); Aguiar y Barreiro (2012). Vale mencionar, de cualquier manera, que el <em>patch</em> desarrollado para controlar granular <em>sampling</em>, después de sumarle nuevas funcionalidades fue adaptado al Kinect (lo que permitió controlar la granulación sonora en cuatro canales por medio de movimientos de los brazos y de las manos). Para la elaboración de una nueva versión de <em>Weaving Rust</em>, esa implementación fue adaptada para el Leap Motion con la intención de controlar la granulación de muestras sonoras en ocho canales por medio del movimiento de las manos y de los dedos.</p>
            <p>Todas esas versiones del <em>patch</em> de <em>granular sampling</em> en sistemas multicanales para el uso con Wiimote/nunchuk, Kinect y Leap Motion derivan de un <em>patch</em> anterior, controlado por <em>mouse</em>, que utilicé en estudio<sup><span id="nota20"><a href="027-n10.xhtml#nota20">20</a></span></sup> (para preparar el material sonoro de algunas de mis obras acusmáticas en ocho canales) y de una otra versión usada en la instalación interactiva I/VOID/O (para distribución aleatoria de los granos sonoros en cuatro canales).<sup><span id="nota21"><a href="027-n10.xhtml#nota21">21</a></span></sup></p>
            <p>Una característica peculiar de una de las versiones desarrolladas para Wiimote/Nunchuk y también de las versiones para Kinect y Leap Motion, es que la distribución de los granos sonoros en el sistema multicanal no sigue procesos aleatorios (como ocurría en las versiones anteriores del <em>patch</em>), sino una distribución controlada por medio del algoritmo <em>Boids</em>, de Craig Reynolds, a partir de una implementación de Eric Singer para Max/MSP.<sup><span id="nota22"><a href="027-n10.xhtml#nota22">22</a></span></sup></p>
            <p>En el algoritmo, que simula el comportamiento emergente de un grupo de animales (una bandada de pájaros, por ejemplo), cada <em>Boids</em> representa un individuo (en el caso del <em>patch</em>, un grano sonoro) cuyas trayectorias derivan de reglas simples de movimientos alrededor de un punto atractor, tales como: evitar colisiones con otros Boids, pero sin distanciarse demasiado de ellos; mantener aproximadamente la misma dirección y la misma velocidad que los demás <em>Boids</em>. De ese modo, por medio de algunos pocos parámetros, emergen movimientos complejos en el conjunto de los <em>Boids</em>.</p>
            <p>En mi primera implementación con el algoritmo <em>Boids</em>, para granulación de muestras sonoras en cuatro canales, «el atractor es controlado por el nunchuk, cuyos movimientos son mapeados para el plano bidimensional donde los Boids se mueven, influenciando, consecuentemente, la espacialización de los granos en la sala de concierto» (Barreiro, 2011, p. 10). En la implementación con el Kinect, también en cuatro canales, el posicionamiento del atractor en el plan bidimensional es controlado por los movimientos de la mano derecha en el aire en los sentidos horizontal (eje X) y vertical (eje Y). El movimiento de la mano derecha para delante y para tras (eje Z) controla la densidad de granos (con base en parámetros como la duración de cada grano y el intervalo temporal entre granos sucesivos). La mano izquierda, a su vez, controla el cambio de la muestra sonora que será granulada (escogida entre tres muestras posibles), la amplitud de los granos y algunas formas de procesamiento como filtro con FFT (<em>Fast Fourier Transform</em>)<sup><span id="nota23"><a href="027-n10.xhtml#nota23">23</a></span></sup> y efecto doppler.</p>
            <p>El principal interés en utilizar algún tipo de control (mismo que de carácter general) sobre la distribución de los granos en el sistema multicanal, por medio del algoritmo <em>Boids</em>, es que este permita formas dinámicas e intuitivas de concentrar los sonidos en determinadas regiones del espacio o de delinear trayectorias en el espacio siempre que esta sea la intención. En ese caso, los movimientos del atractor hacen que los granos sonoros, en el conjunto, describan un movimiento similar acompañándolo en el espacio.</p>
            <p>El <em>patch</em> que controla sonidos granulares en ocho canales con el Leap Motion (generados a partir de muestras sonoras pregrabadas en <em>stereo</em>) fue concebido para generar materiales para la <em>High Stem</em> en dos versiones de <em>Weaving Rust</em> que permiten la improvisación con sonidos electroacústicos en tiempo real. Por medio del rastreo de la posición de una de las manos y de la cantidad de movimientos realizados con los dedos, es posible controlar la duración, la densidad sonora (en virtud de la cantidad de granos) y el registro (ámbito frecuencial) de los sonidos, más allá de sus posiciones y de los desplazamientos en el espacio (por medio del control de la posición del atractor de los <em>Boids</em>).</p>
            <p>Esta posibilidad fue explorada en una versión de <em>Weaving Rust</em> presentada con el sistema MANTIS en el Sonic Fusion Festival – International Explorations in Music, en Salford University (Inglaterra), en abril de 2014. La distribución de las <em>stems</em> en los altoparlantes del sistema fue similar a la de los diagramas presentados en las figuras 3, 4 y 5. En esa versión, la <em>Main Stem</em> y la <em>Distant Stem</em> fueron mantenidas de la misma forma que en la versión acusmática. Los sonidos de la <em>High Stem</em>, a su vez, pasaron a ser generados y manipulados en tiempo real por medio del <em>patch</em> de granulación de muestras en ocho canales controlados con el Leap Motion. Esto permitió realizar un contexto de improvisación musical direccionada.<sup><span id="nota24"><a href="027-n10.xhtml#nota24">24</a></span></sup> La improvisación con los sonidos electroacústicos que constituyen la <em>High Stem</em> no afecta la duración y la estructura general de la obra (las cuales son definidas por la <em>Main Stem</em> y por la <em>Distant Stem</em>). Por otro lado, la flexibilidad en la articulación de los materiales de la <em>High Stem</em> tiene el potencial de influir en la sensación global del transcurso de la obra, o sea, en el tiempo percibido por la escucha.</p>
            <p>También he concebido una tercera versión (aun inédita) de <em>Weaving Rust</em> en la cual la improvisación con los sonidos electroacústicos controlados por el Leap Motion define los materiales musicales presentados en la <em>High Stem</em> y en la <em>Distant Stem</em>, garantizando una mayor flexibilidad en la definición de la duración total de la obra. Los materiales de la <em>Main Stem</em>, aunque sean los mismos de la versión acusmática, son segmentados en diversos pasajes y disparados por medio de un pedal USB, lo que permite que el flujo temporal de la obra pueda ser controlado durante el <em>performance</em>. Eso permite también que secciones de improvisación con sonidos en la <em>High Stem</em> y en el <em>Distant Stem</em> puedan ser incluidas en el transcurso de la obra, provocando alteraciones estructurales en relación a la versión acusmática.</p>
            <p>El desafío para esta versión en tiempo real fue encontrar la manera de generar sonidos largos de lenta evolución temporal para la <em>Distant Stem</em>. Para eso, desarrollé otro <em>patch</em> en Max/MSP para el Leap Motion. Este <em>patch</em> controla sonidos en ocho canales generados a partir de muestras sonoras pregrabadas en <em>stereo</em>. Incluso con muestras relativamente cortas, es posible generar sonidos largos y controlar su registro (la región frecuencial que ocupan) y su complejidad espectral (o sea, determinar la presencia de más o menos parciales –lo que permite generar sonidos compuestos o sonidos con espectro complejo y también ruidosos). Ese <em>patch</em> tiene el potencial de generar drones interesantes, apropiados para la <em>Distant Stem</em>. El <em>patch</em> funciona de la siguiente forma: el resultado de la granulación en ocho canales de una muestra sonora pregrabada pasa por un filtro implementado con FFT que deja pasar solamente las <em>bins</em> con amplitud superior a un límite determinado a partir de la posición de una de las manos en el eje horizontal (identificada por el Leap Motion). El resultado sonoro de este filtro es enviado tanto para los ocho altoparlantes responsables por la reproducción de la <em>Distant Stem</em> como para los ocho <em>delays</em> con <em>feedback</em> (cuyo resultado sonoro también se dirige a los ocho altoparlantes). Cabe destacar que la elección de la muestra sonora, de los parámetros de la granulación (duración de los granos e intervalo temporal entre granos sucesivos), del tiempo de <em>delay</em> y de la cantidad de <em>feedback</em> deben ser definidos previamente, de tal manera que permitan generar los resultados sonoros pretendidos. Otra información importante es que ese <em>patch</em>, que genera material para la <em>Distant Stem</em>, puede funcionar concomitantemente con el <em>patch</em> que genera material para la <em>High Stem</em>, pues cada <em>patch</em> es controlado por una mano diferente.</p>
            <h2 id="consideraciones-finales-1">Consideraciones finales</h2>
            <p>En este trabajo abordé, con base en un ejemplo de mi producción composicional reciente y una breve retrospectiva sobre algunos trabajos anteriores, aspectos relacionados a la concepción y al tratamiento del espacio en la música electroacústica, el uso de interfaces gestuales en procesos interactivos, situaciones de improvisación con sonidos electroacústicos y el desarrollo de aplicaciones en Max/MSP para el control en tiempo real de sonidos electroacústicos en sistemas multicanales usando interfaces gestuales (destacadas para el Leap Motion).</p>
            <p>Por medio del rastreo de los movimientos de las manos y de los dedos, fue posible explorar la generación y el control de sonidos electroacústicos en sistemas multicanales en tiempo real para interactuar con las camadas sonoras grabadas y/o generadas en estudio. Esta investigación tuvo como centro el potencial creativo que la tecnología actual de rastreo de movimiento puede ofrecer para la música compuesta y ejecutada con dispositivos electrónicos, particularmente en el desarrollo de formas creativas de manipulación espectromorfológica y de la espacialidad de los sonidos electroacústicos en tiempo real, viabilizando un abordaje innovador en el campo de la composición/<em>performance</em> electroacústica con sistemas multicanales.</p>
            <p>Búsquedas en internet revelan trabajos y experimentaciones musicales que hacen uso del Leap Motion para la realización de la síntesis y del procesamiento sonoro en tiempo real. Sin embargo, la concepción, la composición y el <em>performance</em> de <em>Weaving Rust</em> exploran no sólo esa posibilidad de manipulación más directa e intuitiva de los parámetros de la síntesis y del procesamiento sonoro con el uso del Leap Motion, sino sobre todo el potencial del control gestual en la manipulación del espacio sonoro en una obra electroacústica para veinticuatro canales. Obras electroacústicas multicanales de esa magnitud son raras (normalmente restrictas a ocho canales, como máximo), lo que contribuye con el desarrollo innovador para el área.</p>
            <p>La flexibilidad para generar sonidos electroacústicos en tiempo real –garantizada por las aplicaciones implementadas– viabiliza alternativas más directas e intuitivas para moldear la obra al ambiente de concierto (las características acústicas de la sala, por ejemplo) por medio de la definición del transcurso temporal de las camadas sonoras con base en los materiales musicales improvisados. Así, en una sala más reverberante, se pueden articular materiales en intervalos temporales más espaciados, mientras que en una sala con poca reverberación podemos realizar articulaciones más veloces de los materiales.</p>
            <p>Este trabajo es una contribución al concepto de <em>live-acousmatic music</em>, formulado por Berezan (2008), y con la idea del <em>fracturing the acousmatic</em>, formulada por Moore (2008), contribuyendo para el debate sobre la exploración de un hibridismo entre el abordaje acusmático (pautada en la composición/control minucioso de los sonidos en estudio) y un enfoque vinculado a las propuestas de improvisación (típicas, en el contexto electroacústico de la <em>laptop music</em>). La investigación realizada proporcionó el desdoblamiento de ese debate en contextos de composición y <em>performance</em> con uso de una interfaz gestual no-háptica (el Leap Motion) y sistemas multicanales; contribuyendo así, con las investigaciones sobre la espacialidad en la música electroacústica y ofreciendo nuevos abordajes para el control en tiempo real de los sonidos en sistemas sonoros multicanales.</p>
            <p>Es necesario destacar todavía el dialogo realizado con la perspectiva reciente de la composición en <em>stems</em> (Wilson y Harrison, 2010), la cual establece una nueva forma de encarar y concebir el espacio en el contexto de la composición acusmática multicanal.</p>
            <p>Juzgo que el uso del abordaje de composición en <em>stems</em> en mi obra <em>Weaving Rust</em> proporcionó resultados musicales interesantes. El tratamiento individualizado de materiales diferentes para los grupos de altoparlantes creó una espacialidad más envolvente que la que normalmente se obtiene con ocho canales. Situaciones de concierto (como las descriptas en este trabajo) en que hay un número mayor de altoparlantes que lo mínimo necesario para la presentación de la obra permiten potencializar el tratamiento espacial compuesto en el estudio, articulando diferentes grados de proximidad y distanciamiento de cada una de las <em>stems</em> en relación al público durante el <em>performance</em> de la obra. Esa versatilidad del abordaje en <em>stems</em>, que viabiliza su adaptación a diferentes sistemas de difusión en concierto, se manifiesta también, por otro lado, en situaciones con sistemas sonoros más pequeños, en los cuales las <em>stems</em> pueden ser adaptadas para un número menor de canales. Tal posibilidad, relatada por Wilson y Harrison (2010), fue testeada con la versión acusmática de la obra <em>Weaving Rust</em> por medio del direccionamiento de las tres <em>stems</em> para un único grupo de ocho altoparlantes. Aunque el resultado en venticuatro canales (o más) sea más envolvente, la reducción para ocho canales no compromete sustancialmente la articulación de los materiales musicales, viabilizando esa opción en situaciones de concierto más restrictivas.</p>
            <p>El hecho de haber creado tres versiones diferentes de <em>Weaving Rust</em> permite también que, en investigaciones futuras, podamos comparar entre estas versiones para averiguar en qué medida los materiales musicales articulados en tiempo real (improvisados) alteran la percepción de transcurso temporal y la propia estructura de la obra. En otras palabras, una comparación como esa puede permitir evaluar las interferencias establecidas entre los distintos materiales musicales y el tejido estructural global de la obra –una evaluación, por lo tanto, sobre las relaciones entre micro y macroestructura musical–.</p>
       </section>
       <section epub:type="bibliography" class="sin-borde">
            <h2 id="referencias-bibliográficas-5">Referencias bibliográficas</h2>
            <p class="frances">Aguiar, D. S. &amp; Barreiro, D. L. (2012). Estratégias para o controle gestual de sons eletroacústicos em tempo real. <em>Horizonte Científico, 6</em>(1), pp. 1-20. Disponible en: <a target="_blank" href="http://www.seer.ufu.br/index.php/horizontecientifico/article/view/13427/8076">http://www.seer.ufu.br/index.php/horizontecientifico/article/view/13427/8076</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">Barreiro, D. L. (2010). Considerations on the Handling of Space in Multichannel Electroacoustic Works. <em>Organised Sound, 15</em>(3), pp. 290-296. Disponble en: <a target="_blank" href="https://doi.org/10.1017/S1355771810000294">https://doi.org/10.1017/S1355771810000294</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">____________ (2011). Manipulação de amostras sonoras em contexto interativo. <em>Revista do EIMAS, 2</em>(1). Juiz de Fora: Universidade Federal de Juiz de Fora. Disponible en: <a target="_blank" href="http://www.ufjf.br/anais_eimas/files/2012/02/Manipula%C3%A7%C3%A3o-de-amostras-sonoras-em-contexto-interativo-Daniel-Barreiro.pdf">http://www.ufjf.br/anais_eimas/files/2012/02/Manipula%C3%A7%C3%A3o-de-amostras-sonoras-em-contexto-interativo-Daniel-Barreiro.pdf</a> [Acceso en: 12/01/17].</p>
            <p class="frances">Barreiro, D. L., Abreu, S. C., Carvalho, A. C. P. L. F. (2012). Linking Sound, Image and Space in an Interactive Installation: Real-Time Sound Synthesis and Live Image in I/VOID/O. <em>Ideas Sonicas/Sonic Ideas</em>, Año 4, (8). Morelia, Michoacán, México: Centro Mexicano para la Música y las Artes Sonoras (CMMAS), pp. 61-69.</p>
            <p class="frances">Barreiro, D. L., Keller, D. (2010). Composição com modelos sonoros: fundamentos e aplicações eletroacústicas. En: D. Keller y R. Budasz (Eds.). <em>Criação Musical e Tecnologias: Teoria e Prática Interdisciplinar</em>. Goiânia: ANPPOM, pp. 97-126. Disponible en: <a target="_blank" href="http://www.anppom.com.br/ebooks/index.php/pmb/catalog/view/2/3/36-1">http://www.anppom.com.br/ebooks/index.php/pmb/catalog/view/2/3/36-1</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">Barreiro, D. L., Traldi, C. A., Cintra, C. L. A., Menezes Júnior, C. R. F. (2010). Instrumentos acústicos e meios eletrônicos em tempo real: estratégias de improvisação coletiva. <em>Revista EIMAS – Encontro Internacional de Música e Arte Sonora 2010</em>. Juiz de Fora: UFJF. Disponible en: <a target="_blank" href="https://www.researchgate.net/publication/291161842_Instrumentos_acusticos_e_meios_eletronicos_em_tempo_real_estrategias_de_improvisacao_coletiva">https://www.researchgate.net/publication/291161842_Instrumentos_acusticos_e_meios_eletronicos_em_tempo_real_estrategias_de_improvisacao_coletiva</a> [Fecha de acceso: 14/01/17].</p>
            <p class="frances">Berezan, D. (2008). <em>In Flux: a new approach to sound diffusion performance practice for fixed media music</em>. Disponible en: <a target="_blank" href="http://quod.lib.umich.edu/cgi/p/pod/dod-idx/in-fluxa-new-approach-to-sound-diffusion-performance.pdf?c=icmc;idno=bbp2372.2008.003">http://quod.lib.umich.edu/cgi/p/pod/dod-idx/in-fluxa-new-approach-to-sound-diffusion-performance.pdf?c=icmc;idno=bbp2372.2008.003</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">Fischman, R. (2013). A Manual Actions Expressive System (MAES). <em>Organised Sound, 18</em>(3), pp. 328-345. Disponible en: <a target="_blank" href="https://doi.org/10.1017/S1355771813000307">https://doi.org/10.1017/S1355771813000307</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">Harrison, J. (1999). Sound, Space, Sculpture: some thoughts on the <code>what',</code>how' and `why' of sound diffusion. <em>Organised Sound, 3</em>(2), pp. 117-127. Disponible en: <a target="_blank" href="https://doi.org/10.1017/S1355771898002040">https://doi.org/10.1017/S1355771898002040</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">_________ (2000). "Imaginary Space ­ Spaces in the Imagination". <em>Australasian Computer Music Conference 1999, Keynote Address, eContact!, 3</em>(2), Montréal: CEC. Disponible en: <a target="_blank" href="http://cec.concordia.ca/econtact/ACMA/ACMConference.htm">http://cec.concordia.ca/econtact/ACMA/ACMConference.htm</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">_________ (2016). Round the World in Sixty Minutes: approaches to the evocation of space, place and location in recent multichannel works. <em>Ouvirouver, 12</em>(1), pp. 14-29. Disponible en: <a target="_blank" href="http://dx.doi.org/10.14393/OUV18-v12n1a2016-1">http://dx.doi.org/10.14393/OUV18-v12n1a2016-1</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">Kim-Boyle, D. (2006). Spectral and Granular Spatialization with Boids. <em>Proceedings of the 2006 International Computer Music Conference</em>, pp.139-142. New Orleans: ICMA, Disponible en: <a target="_blank" href="http://quod.lib.umich.edu/cgi/p/pod/dod-idx/spectral-and-granularspatialization-with-boids.pdf?c=icmc;idno=bbp2372.2006.031">http://quod.lib.umich.edu/cgi/p/pod/dod-idx/spectral-and-granularspatialization-with-boids.pdf?c=icmc;idno=bbp2372.2006.031</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">Lippe, C. (1994). Real-time granular sampling using the IRCAM signal processing workstation. <em>Contemporary Music Review, 10</em>, pp. 149-155. Disponible en: <a target="_blank" href="http://dx.doi.org/10.1080/07494469400640381">http://dx.doi.org/10.1080/07494469400640381</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">Moore, A. (2008). <em>Fracturing the Acousmatic: Merging improvisation with disassembled acousmatic music</em>. Disponible en: <a target="_blank" href="http://www.shef.ac.uk/polopoly_fs/1.26358!/file/ajmICMCfinalfracture.pdf">http://www.shef.ac.uk/polopoly_fs/1.26358!/file/ajmICMCfinalfracture.pdf</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">Popp, C. (2014). <em>Portfolio of original compositions</em> [Tesis de Doctorado]. Manchester: University of Manchester.</p>
            <p class="frances">Settel, Z., Lippe, C. (1994). Real-Time Timbral Transformation: FFT-based Resynthesis. <em>Contemporary Music Review, 10</em>(2), pp. 171-180. Reino Unido: Harwood Academic Publishers. Disponible en: <a target="_blank" href="http://dx.doi.org/10.1080/07494469400640401">http://dx.doi.org/10.1080/07494469400640401</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">_________ (1995). <em>Real-time Musical Applications using Frequency-domain Signal Processing</em>. Disponible en: <a target="_blank" href="https://www.researchgate.net/profile/Cort_Lippe/publication/3621631_Real-time_musical_applications_using_frequency_domain_signal_processing/links/5781615908ae9485a43bdef9.pdf">https://www.researchgate.net/profile/Cort_Lippe/publication/3621631_Real-time_musical_applications_using_frequency_domain_signal_processing/links/5781615908ae9485a43bdef9.pdf</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">_________ (1998). Real-time Frequency Domain Signal Processing on the Desktop. <em>Proceedings of the ICMC1998</em>, pp. 142-149. San Francisco: ICMA. Disponible en: <a target="_blank" href="https://www.researchgate.net/profile/Cort_Lippe/publication/240207753_Real-time_Frequency-Domain_Digital_Signal_Processing_on_the_Desktop/links/00b7d52a0b10eca681000000.pdf">https://www.researchgate.net/profile/Cort_Lippe/publication/240207753_Real-time_Frequency-Domain_Digital_Signal_Processing_on_the_Desktop/links/00b7d52a0b10eca681000000.pdf</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">_________ (1999). Audio-rate control of FFT-based processing using few parameters. <em>Proceedings of the 2nd COST G-6 Workshop on Digital Audio Effects (DAFx99)</em>, Trondheim. Disponible en: <!-- <a target="_blank" href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=046701EF53D2307506C6D481C4D366A5?doi=10.1.1.33.5642&rep=rep1&type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=046701EF53D2307506C6D481C4D366A5?doi=10.1.1.33.5642&rep=rep1&type=pdf</a> --> <mark>Liga caída</mark> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">Smalley, D. (2007). Space-form and the acousmatic image. <em>Organised Sound, 12</em>(1), pp. 35­58. Disponible en: <a target="_blank" href="https://doi.org/10.1017/S1355771807001665">https://doi.org/10.1017/S1355771807001665</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">Traldi, C. A., Aguiar, D. S., Barreiro, D. L. (2011). [Wii]mproviso: controle gestual numa improvisação com sons eletroacústicos em tempo real. <em>Anais do 13o. Simpósio Brasileiro de Computação Musical – SBCM 2011</em>. Vitória/Porto Alegre: FAESA/UFRGS, pp. 1-12. Disponible en: <a target="_blank" href="http://www.numut.iarte.ufu.br/sites/numut.iarte.ufu.br/files/Anexos/Bookpage/wiimproviso_sbcm2011.pdf">http://www.numut.iarte.ufu.br/sites/numut.iarte.ufu.br/files/Anexos/Bookpage/wiimproviso_sbcm2011.pdf</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">Wilson, S. (2008). Spatial Swarm Granulation. <em>Proceedings of the 2008 International Computer Music Conference</em>, Belfast, Irlanda del Norte. Disponible en: <a target="_blank" href="http://eprints.bham.ac.uk/237/1/cr1690.pdf">http://eprints.bham.ac.uk/237/1/cr1690.pdf</a> [Fecha de acceso: 12/01/17].</p>
            <p class="frances">Wilson, S., Harrison, J. (2010). Rethinking the BEAST: Recent developments in multichannel composition at Birmingham ElectroAcoustic Sound Theatre. <em>Organised Sound, 15</em>(3), pp. 239-250. Disponible en: <a target="_blank" href="https://doi.org/10.1017/S1355771810000312">https://doi.org/10.1017/S1355771810000312</a> [Fecha de acceso: 12/01/17].</p>
        </section>
    </body>
</html>
