<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="es" lang="es">
    <head>
        <meta charset="UTF-8" />
        <title>Notas</title>
        <link href="../css/principal.css" rel="stylesheet" type="text/css" />
    </head>
    <body epub:type="chapter">
        <section>
          <h1>Notas</h1>
        </section>
        <section class="sin-borde">
          <p class="sangria"><sup><span id="nota1"><a href="026-c10.xhtml#nota1">1</a></span></sup>El presente trabajo se basa principalmente en resultados de una investigación financiada por CNPq (Posdoctorado en el exterior). También son mencionados resultados de investigaciones anteriores financiadas por Capes (Doctorado pleno en el exterior), por el propio CNPq (Posdoctorado júnior en el país) y por Fapemig (Auxilio a la investigación).</p>
          <p><sup><span id="nota2"><a href="026-c10.xhtml#nota2">2</a></span></sup>Al mencionar la composición de los sonidos, considero aquí tanto la esfera de la música electroacústica (por medio de la síntesis y/o procesamiento sonoro) así como de la música instrumental (por medio de la instrumentación/orquestación, del tratamiento de los diferentes parámetros sonoros y del uso de las técnicas instrumentales, sean ellas tradicionales y/o expandidas).</p>
          <p><sup><span id="nota3"><a href="026-c10.xhtml#nota3">3</a></span></sup><em>Weaving Rust</em>, basada en sonidos de platos de percusión, sonidos de la puerta de un horno viejo y oxidado y sonidos de una máquina de costura antigua, fue compuesta durante mi investigación de posdoctorado en Novars Research Centre –University of Manchester– de mayo de 2013 a abril de 2014. La investigación tuvo la supervisión del Dr. David Berezan y contó con una beca de investigación del Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq) –agencia federal brasileña de fomento a la investigación.</p>
          <p><sup><span id="nota4"><a href="026-c10.xhtml#nota4">4</a></span></sup>He realizado el doctorado de enero de 2003 a enero de 2007 en la University of Birmingham (Inglaterra), bajo la orientación de Jonty Harrison y con beca de la Coordenadoria de Aperfeiçoamento de Pessoal de Nível Supeior (Capes) –agencia federal brasileña de fomento al posgrado. En esa oportunidad, actué junto al Birmingham Electro-Acoustic Sound Theatre (BEAST), que es la designación tanto del grupo de compositores actuantes en los estudios de música electroacústica de la University of Birmingham así como del sistema sonoro concebido y creado por Jonty Harrison para la difusión de obras electroacústicas en diferentes ambientes de concierto. El arsenal de altoparlantes del BEAST recibió sustituciones y fue creciendo a lo largo de los años, teniendo actualmente cerca de una centena de altoparlantes. Desde su origen, el sistema BEAST constituye una de las más importantes referencias, en el escenario internacional, para la presentación de obras electroacústicas en concierto. Para referencias sobre la concepción del BEAST, ver: Harrison (1999) y Harrison (2000).</p>
          <p><sup><span id="nota5"><a href="026-c10.xhtml#nota5">5</a></span></sup>Según Smalley (<em>apud.</em> Harrison, 1999, pp. 124­–125), la difusión sonora –o sea, la presentación de una obra electroacústica en un espacio de escucha (<em>listening space</em>) por medio de un conjunto de varios altoparlantes– articula el espacio compuesto de las obras (<em>composed space</em>), constituyendo aquello que se llama de espacio difundido (<em>diffused space</em>). Sobre esta cuestión, ver también: Smalley (2007).</p>
          <p><sup><span id="nota6"><a href="026-c10.xhtml#nota6">6</a></span></sup>Entre estas obras, la única que no es acusmática es <em>Open Field</em>, compuesta para violín y sonidos electroacústicos en ocho canales. Para un enfoque sobre algunas de ellas, ver: Barreiro (2010).</p>
          <p><sup><span id="nota7"><a href="026-c10.xhtml#nota7">7</a></span></sup>Posteriormente, tales <em>patches</em> fueron reunidos en el paquete BEASTtools. Disponible en: <a target="_blank" href="http://www.birmingham.ac.uk/facilities/ea-studios/research/beasttools.aspx">http://www.birmingham.ac.uk/facilities/ea-studios/research/beasttools.aspx</a> [Fecha de acceso: 05/05/17].</p>
          <p><sup><span id="nota8"><a href="026-c10.xhtml#nota8">8</a></span></sup>Una reducción estéreo de la versión acusmática de la obra se encuentra disponible en: <a target="_blank" href="https://drive.google.com/open?id=0B10Z_t2sRaarOFdnRjQ4bDB5TFE">https://drive.google.com/open?id=0B10Z_t2sRaarOFdnRjQ4bDB5TFE</a> (duración: 13'11''). Nota de programa de <em>Weaving Rust</em>: <em>A sewing machine, a rusty oven, cymbals... Threads interlaced, gestures that make the fabric... Textures building up from rust</em>.</p>
          <p><sup><span id="nota9"><a href="026-c10.xhtml#nota9">9</a></span></sup>Sobre la concepción de composición en <em>stems</em>, ver también: Harrison (2016) y Popp (2014). La dificultad en traducir el término <em>stem</em> por un equivalente que corresponda a su sentido original, me ha llevado a mantener el término en inglés. <em>Estrato</em> podría haber sido una alternativa de traducción, pero no me pareció totalmente adecuada.</p>
          <p><sup><span id="nota10"><a href="026-c10.xhtml#nota10">10</a></span></sup><em>Ear-level</em>, en el original.</p>
          <p><sup><span id="nota11"><a href="026-c10.xhtml#nota11">11</a></span></sup><em>Figure and landscape elements</em>, en el original.</p>
          <p><sup><span id="nota12"><a href="026-c10.xhtml#nota12">12</a></span></sup>Desde este punto en adelante, la versión de <em>Weaving Rust</em> compuesta integralmente en estudio será llamada "versión acusmática" para diferenciarla de las versiones realizadas por la generación y el control de los sonidos en tiempo-real en el momento de la <em>performance</em>.</p>
          <p><sup><span id="nota13"><a href="026-c10.xhtml#nota13">13</a></span></sup>En las figuras, el espacio destinado al público es representado por un cuadrado negro.</p>
          <p><sup><span id="nota14"><a href="026-c10.xhtml#nota14">14</a></span></sup>Considero que hay aquí una situación de improvisación direccionada porque las camadas compuestas en estudio constituyen un contexto musical con lo cual los sonidos improvisados dialogan.</p>
          <p><sup><span id="nota15"><a href="026-c10.xhtml#nota15">15</a></span></sup>Tales investigaciones han sido realizadas en la Universidad Federal de Uberlândia (UFU) en el ámbito del Núcleo de Música e Tecnología (NUMUT), un grupo de investigación que congrega docentes, alumnos de grado y posgrado con interés en el área de música y tecnología. Una de estas investigaciones fue financiada por la Fundação de Amparo à Pesquisa do Estado de Minas Gerais (Fapemig). Las investigaciones en general envuelven algún componente de producción artística, tales como performances musicales con el MAMUT (Grupo Música Aberta da UFU), un grupo formado por profesores vinculados al NUMUT que tiene como foco principal la práctica de la improvisación musical contemporánea (también llamada de improvisación libre) envolviendo instrumentos acústicos y medios electroacústicos. El grupo se presentó en diversas ocasiones, en eventos locales y nacionales, algunas veces con la participación de investigadores invitados de otras instituciones académicas.</p>
          <p><sup><span id="nota16"><a href="026-c10.xhtml#nota16">16</a></span></sup>Como son dispositivos que deben ser agarrados con las manos para que los botones y los acelerómetros sean utilizados, tanto el Wiimote y el nunchuk dificultan el acceso a otros dispositivos (como una mesa de difusión sonora, por ejemplo) para que sean controlados durante un <em>performance</em>. El Kinect no presenta ese inconveniente, pues los movimientos son rastreados sin que sea necesario agarrar objetos. Sin embargo, los experimentos realizados (con el uso de la aplicación Synapse para establecer la comunicación del Kinect con la computadora) han demostrado un cierto retraso en la identificación de los movimientos. Además, el Synapse tarda algunos segundos para identificar el cuerpo de la persona que se pone delante al Kinect para que los movimientos sean rastreados, lo que puede generar dificultades en la configuración del sistema antes del <em>performance</em>. Sobre el Synapse, ver: <a target="_blank" href="http://synapsekinect.tumblr.com/">http://synapsekinect.tumblr.com/</a> [Fecha de acceso: 05/05/17].</p>
          <p><sup><span id="nota17"><a href="026-c10.xhtml#nota17">17</a></span></sup>El acceso a estas implementaciones se encuentra disponible en: <a target="_blank" href="http://www.numut.iarte.ufu.br/downloads-partituras-e-patches">http://www.numut.iarte.ufu.br/downloads-partituras-e-patches</a> [Fecha de acceso: 05/05/17].</p>
          <p><sup><span id="nota18"><a href="026-c10.xhtml#nota18">18</a></span></sup>Realizado con la colaboración de Danilo Silva Aguiar.</p>
          <p><sup><span id="nota19"><a href="026-c10.xhtml#nota19">19</a></span></sup>En la literatura del área, la granulación de muestras sonoras grabadas recibe, a veces, la denominación de <em>granular sampling</em> –ver: Lippe (1994)– reservándose el término <em>síntesis granular</em> para los procesos granulares en que la señal resulta de un proceso de síntesis sonora.</p>
          <p><sup><span id="nota20"><a href="026-c10.xhtml#nota20">20</a></span></sup>Tal <em>patch</em> deriva de una implementación de Peter Batchelor, que, a su vez, incorpora características de un <em>patch</em> anterior de Erik Oña –ver: Barreiro (2010) y Barreiro y Keller (2010).</p>
          <p><sup><span id="nota21"><a href="026-c10.xhtml#nota21">21</a></span></sup>Ver: Barreiro et al. (2012). Vale destacar que la incorporación de formas de control por medio de la interfaz gestual constituye un desarrollo que había sido previsto en Barreiro (2010, p. 295).</p>
          <p><sup><span id="nota22"><a href="026-c10.xhtml#nota22">22</a></span></sup>Para acceso a la implementación de Eric Singer, ver: <a target="_blank" href="http://ericsinger.com/cyclopsmax.html">http://ericsinger.com/cyclopsmax.html</a> [Fecha de acceso: 05/05/17]. El <em>patch</em> de <em>granular sampling</em> para control con el Wiimote utilizando el algoritmo <em>Boids</em> fue descrito en Barreiro (2011). De acuerdo con el relato en Barreiro (2010), trabajos anteriores de implementación de síntesis granular/<em>granular sampling</em> utilizando el algoritmo <em>Boids</em> para la distribución de los granos sonoros ya habían sido realizados por Kim-Boyle (2006) y Wilson (2008), aunque sin el uso de interfaces de control gestual. Mi interés por el algoritmo <em>Boids</em> deriva de una investigación sobre procesos computacionales bio-inspirados que realizé en 2008 durante un postdoctorado en la USP de San Carlos, con beca del CNPq y supervisión del Dr. André Carlos Ponce de Leon Ferreira de Carvalho.</p>
          <p><sup><span id="nota23"><a href="026-c10.xhtml#nota23">23</a></span></sup>Para abordajes sobre implementaciones con <em>Fast Fourier Transform</em>, ver: Settel y Lippe (1994; 1995; 1998; 1999).</p>
          <p><sup><span id="nota24"><a href="026-c10.xhtml#nota24">24</a></span></sup>Mis implementaciones anteriores con el Wiimote/Nunchuk y el Kinect habían sido realizadas para controlar sonidos electroacústicos en situaciones de improvisación libre. La implementación con el Leap Motion, aunque haya sido posteriormente utilizada en improvisaciones libres con instrumentos acústicos y sonidos electroacústicos, fue inicialmente desarrollada como parte integrante de <em>Weaving Rust</em>, instituyendo, así, una situación de improvisación dirigida.</p>
        </section>
    </body>
</html>
